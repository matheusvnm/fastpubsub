
# What we need to do

We are developing a framework for working with Google PubSub called StarConsumers.
We move it to the `old/` directory, since we will need to reimplement it from scratch.
The reason is that we found a new framework called Faststream.  It has capabilities 
that are similiar to the framework we are creating plus some new ones. 

However, the Google PubSub support it has is poor and lacks the Google's APIs features.

You can see the he capabilities related to the Starconsumers and Faststream the respective directories `old/starconsumers` and `faststream/`. Feel free to explore the files of both projects to get more context.

The task we need to do is to create a version of StarConsumers that adds some of the selected Faststream 
features in the code while keeping the features of StarConsumers. 


## Features that must change to become similar from Starconsumers from FastStream.
- The `TopicConsumer` should become a `Broker` class, similar to FastStream. In the broker class we should configure the PubSub's project_id. The topic should be handleded at subscription level.
- The `@consumer.task()` syntax should change for something like `@broker.subscriber(alias="yourname", subscription_name="", topic_name="", ... other subscriptions policies)` syntax.
- The `StarConsumer` class should have hooks for on_startup, after_startup, on_shutdown and after_shutdown. These can be sync and async callables.
- Full type safety with comprehensive type hints.
- Clear error messages and debugging support.
- Extensive documentation and examples
- We must have a way fro breaking down the `Broker` class in multiple `BrokerRouter` as we do in faststream.
- We must have two types of middlewares, one for subscriptions only and another BaseMiddleware for subscriptions and publishers.
- We must have a way of using the broker/router to publish the messages `broker.publish` or get the publisher from the broker/router to publish the message.
- We do not need dependency injection using Depends.

## The rules for StarConsumers implementation
- We must not have subscribers with the same alias or subscription_name.
- We must keep the multi-process architecture with one process per subscription.
- We must have process health monitoring and connection tracking.
- We must keep the APM (Application Performance Monitoring) integration.
- We must keep the resource usage monitoring using psutil.
- We must keep the structured logging with contextual information (trace IDs, span IDs, message IDs).
- We must keep exception handling with proper logging and message acknowledgment
- We must keep support for DROP and RETRY exceptions for fine-grained message flow control.
- We must keep automatic message acknowledgment/negative acknowledgment based on handler success



We will provide you with the example of code the user will face when creating a app using starconsumers. 
We must follow this structure. All the code you write to make this work must be in the starconsumers/ directory.




## Some code example of what we expect with comments

```python
# The project must only allow Python 3.12 and above.

# We must have a logger that is default to the application.
# The user should be encorajed to use it.
# We can use the already existing logger. Its good enough.




# The default PubSubMessage should look like this.
@dataclass(frozen=True)
class PubSubMessage:
    id: str
    size: int
    data: bytes
    attributes: dict[str, str]
    delivery_attempt: int | None = 0


# We should have two types of middlewares.
# The publisher middleware to add more context and data when using the broker.publish or publisher.publish
# The subscriber middleware to add more context and data when receiving messages


## Their implementation should like this.
## The users must extend them to apply their own logic.

@dataclass
class BaseSubscriberMiddleware:

    next_call: "BaseSubscriberMiddleware"

    # In the middleware, the message is always the pubsubmessage even in subscribers with basemodel serialization.
    async def on_consume(self, message: PubSubMessage):
        return self.next_call.on_consume(message=message)


@dataclass
class BasePublisherMiddleware:

    next_call: "BasePublisherMiddleware"
    
    async def on_publish(self, data: dict, ordering_key: str = "", attributes: dict = None):
        return self.next_call.on_publish(data=data, ordering_key=ordering_key, attributes=attributes)


## The examples bellow use the implementations cited above


from starconsumers import logger
from starconsumers import BaseSubscriberMiddleware, BasePublisherMiddleware 
from starconsumers import get_apm_provider


from dataclass import dataclasses
from pydantic import BaseModel

# The filter expressions are allowed
FILTER_EXPRESSION = 'attributes.type="event"'



class SomeGlobalSubscriberMiddleware(BaseSubscriberMiddleware):

    async def on_consume(self, message: PubSubMessage):
        logger.info("I will only me called by the router's subscribers")
        return self.next_call.on_consume(message=message)

class SomeRouterSubscriberMiddleware(BaseSubscriberMiddleware):
    async def on_consume(self, message: PubSubMessage):
        logger.info("I will only me called by the router's subscribers")
        return self.next_call.on_consume(message=message)



## Middlewares
class SomeGlobalPublisherMiddleware(BasePublisherMiddleware):

    async def on_publish(self, data: dict, ordering_key: str = "", attributes: dict = None):
        logger.info("I will be called in all publishes")
        return self.next_call.on_publish(data=data, ordering_key=ordering_key, attributes=attributes)



class SomeRouterPublisherMiddleware(BasePublisherMiddleware):
    async def on_publish(self, data: dict, ordering_key: str = "", attributes: dict = None):
        logger.info("I will be called in all publishes called by router")
        return self.next_call.on_publish(data=data, ordering_key=ordering_key, attributes=attributes)





# The message.data can be serialized into a base model
class User(BaseModel)
    id: int
    name: str

class Command(BaseModel):
    name: str


# The broker is the class we must use to connect to PubSub.
# Internally we must handle the auth checks by getting the env vars.
# PUBSUB_EMULATOR_HOST OR GOOGLE_APPLICATION_CREDENTIALS
broker = Broker(project_id="some_project", middlewares=[SomeGlobalPublishedMiddleware, SomeGlobalSubscriberMiddleware])


# These are the message handlers used to handle messages.
# They can only be async!
# In case of serialization fail we must drop the message
@broker.subscriber(alias="mysubscriber", subscription_name="mysubscription", topic_name="mytopic")
async def get_user_message(user: User):
    logger.info(user)

    attributes = {"type": "event"}
    await broker.publish("mysecondtopic", data={"ola": "mundo"}, ordering_key=user.id, attributes=attributes)


# We must allow the user to ge
publisher = broker.publisher("prefix.mythirdtopic")

@broker.subscriber(alias="mysubscriber2", subscription_name="mysubscription", topic_name="mysecondtopic", filter=FILTER_EXPRESSION)
async def get_hello_world_from_user(message: PubSubMessage):
    logger.info(f"User {message.ordering_key} sent a {message.data}")

    # We will only allow json-based messages to be received and sent!
    await publisher.publish(data={"command": "abc"},  ordering_key=message.ordering_key, attributes={"type": "command"})





# Bydefault there is not prefix, but we may have them.
# You can have brokers with the same prefix. As long as their subscriptons' handlers subscription_name and aliases do not conflict
router = BrokerRouter(prefix="some_prefix",  middlewares=[SomeRouterPublisherMiddleware, SomeRouterSubscriberMiddleware])

# The is no prefix applied to published
router_publisher = router.publisher("mylasttopic")


# The subscriptions informations will be created using the router prefix.
# Hence the subscribers bellow will not have conflict with the above.
# For instance:
# topic_name="some_prefix.{topic_name}"
# subscription_name="some_prefix.{subscription_name}" 
# alias="some_prefix.{alias}" 

@router.subscriber(alias="mysubscriber", subscription_name="mysubscription", topic_name="mythirdtopic")
async def do_something2(command: Command, attributes: MessageAttributes):
    logger.info(f"The user sent the command {command.name}")

    if command.name == "abc":
        logger.info("")
        raise DropException()

    apm = get_apm_provider()
    apm.record_custom_event("Commands", params={"command_name": command.name})


    router.publish(topic_name="mylasttopic",data={"event_state": "processed"})
    router_publisher.publish(data={"event_state": "processed"})


broker.include_router(router)
app = StarConsumers(broker=broker)


@app.on_startup
async def start_func():
    logger.info("We will start the application now")


@app.on_shutdown
async def shutdown_func():
    logger.info("We will start the application shutdown now")


@app.after_startup
async def something_sync():
    logger.info("The application is up. We will send a message!")
    await broker.publish(topic_name="mytopic", data={"id": 123, "name": "John"})


@app.after_shutdown
async def after_shutdown_func():
    logger.info("The application is down. So sad")


## The application should be run with
# starconsumers run <module_name>:<app_variable_name> --subscription mysubscriber
# OR to run all subscriptions
# starconsumers run <module_name>:<app_variable_name>

```


